# Practical Machine Learning: Predictive Assignment

## Loading and preprocessing the data  
Load the data,  this data came from the study described at
```
http://groupware.les.inf.puc-rio.br/har
```
```{r}
pml.training <- read.csv("~/Classes/MOOC/Johns Hopkins Course Materials/Practical Machine Learning/Prediction Assignment/pml-training.csv")
pml.testing <- read.csv("~/Classes/MOOC/Johns Hopkins Course Materials/Practical Machine Learning/Prediction Assignment/pml-testing.csv")
```
Many of the variables are empty or have an excessive number of missing values, we will remove them first.

```{r}
names(pml.training)[apply(is.na(pml.training),2,sum)>100]
trainpml<-pml.training[,names(pml.training)%in%names(pml.training)[apply(is.na(pml.training),2,sum)<100]]
testpml<-pml.testing[,names(pml.training)%in%names(pml.training)[apply(is.na(pml.training),2,sum)<100]]
table(trainpml$classe,trainpml$user_name)
```
It appears that each class is about the same size, A tends to be a bit larger, and each user equally represented.  

Now looking at the data, it appears that the training data has summary numbers such as ```max_roll_belt``` that are not in the testing data set.  We will remove them as well as the time stamps.

```{r}
names(trainpml)[c(1,3,4,5,6,7,12,13,14,15,16,17,18,19,20,43,44,45,46,47,48,52,53,54,55,56,57,58,59,60,74,75,76,77,78,79,80,81,82)]
trainpml<-trainpml[,-c(1,3,4,5,6,7,12,13,14,15,16,17,18,19,20,43,44,45,46,47,48,52,53,54,55,56,57,58,59,60,74,75,76,77,78,79,80,81,82)]
testpml<-testpml[,-c(1,3,4,5,6,7,12,13,14,15,16,17,18,19,20,43,44,45,46,47,48,52,53,54,55,56,57,58,59,60,74,75,76,77,78,79,80,81,82)]
```
Some of the variables do not have a great deal of variation, such as the ones with total acceleration, but I will leave them in the model.  I suspect they will not be important predictors.  

## Cross-validation for an estimate of error   
We will now create 5 folds for cross-validation and then run a random forest model.
```{r message=FALSE}
library(randomForest)
set.seed(1001)
folds=sample(1:5,nrow(trainpml),replace=TRUE)
length(folds)
table(folds)
```
Now building the model and estimating error rate using cross-validation.

```{r}
set.seed(3829)
cv.error=rep(NA,5)
for (i in 1:5){
  modtemp<-randomForest(classe~.,data=trainpml[folds!=i,])
  predtemp<-predict(modtemp,newdata=trainpml[folds==i,])
  cv.error[i]<-1-sum(diag(table(predtemp,trainpml$classe[folds==i])))/length(predtemp)
}
cv.error
```
Based on cross-validation, the estimate for the out of sample error is .43%.  

## Building the model and predicting test data
Finally we will build a model on all the training data and then use it to predict the test data.

```{r}
modfinal<-randomForest(classe~.,data=trainpml,importance=TRUE)
modfinal
```
Notice that the out of bag estimate of error, .27%, is a little optimistic relative to the cross-validated error, .43%.  

A plot of the importance of variables gives you some idea of which variables are important predictors.  

```{r}
varImpPlot(modfinal)
```

Finally we will predict the class of the 20 testing observations.  

```{r}
predfinal<-predict(modfinal,newdata=testpml)
predfinal
```

This concludes the project.  

```{r echo=FALSE,results='hide',message=FALSE}
#Code for the web site
answers=as.character(predfinal)
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

```



